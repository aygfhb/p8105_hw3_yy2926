---
title: "Homework 3"
author: "Yuxin"
date: "2018.10.12"
output: github_document
---
```{r setup, include=FALSE}
devtools::install_github("p8105/p8105.datasets")
library(tidyverse)
library(readxl)
library(p8105.datasets)
```
Problem 1
```{r Problem1}
data("brfs_smart2010")
brfss_data = brfss_smart2010 %>%
janitor::clean_names() %>%
filter(topic == "Overall Health") %>%
filter(response == "Excellent"| response == "Very good" | response == "Good" | response == "Fair" | response == "Poor")
brfss_data$response = factor (brfss_data$response,levels = c("Excellent","Very good","Good","Fair","Poor"))
brfss_data
```
*** Q1: In 2002, which states were observed at 7 locations?

*** A1: Three states CT,FL,NC were observed at 7 locations in 2002.
```{r Question1.1}
brfss_data %>%
group_by(year,locationabbr) %>%
summarize(n_obs=n()/5) %>%
filter(year == "2002",n_obs==7)
```

*** Q2: Make a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010.

```{r Question1.2}
observation_state <- count(count(brfss_data,year,locationabbr,locationdesc),year,locationabbr)
ggplot(data=observation_state,aes(x=year,y=nn,color=locationabbr))+ylab("number of location")+geom_line(size=0.5)
```
*** Q3 Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.

```{r question1.3}
brfss_excellent = subset(brfss_data,locationabbr == "NY" & response=="Excellent"&(year==2002 | year==2006 | year==2010)) %>%
group_by(year) %>%
summarize(mean_proportion = mean(data_value),
          sd_proportion = sd(data_value))
brfss_excellent
```

*** Q4 For each year and state, compute the average proportion in each response category (taking the average across locations in a state). Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time.

```{r question1.4}
brfss_proportion = brfss_data %>%
group_by(year,locationabbr,response) %>%
summarize(mean_data = mean(data_value))
ggplot(data=brfss_proportion, aes(x=year, y= mean_data, color=response))+
  geom_smooth(se=FALSE)+
  facet_grid(.~response)
```


Problem 2
```{r Problem2}
data("instacart")
instacart_data = instacart %>%
janitor::clean_names()
aisle_summary = count(instacart_data,aisle_id)
```

*** Q1: How many aisles are there, and which aisles are the most items ordered from?

*** A1: There are `r NROW(aisle_summary$aisle_id)` aisles there. The aisles id of the most items ordered from is `r which.max(aisle_summary$n)`, and it is fresh vegetables. 


*** Q2:Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.

```{r Question2.2}
aisle_information <- unique(instacart_data[,c("aisle_id","aisle")])
aisle_information <- aisle_information[order(aisle_information$aisle_id),]
```

*** Q3:Make a table showing the most popular item in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.


*** Q4:Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).



